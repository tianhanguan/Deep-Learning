{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import useful modules\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import copy\n",
    "import random\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set directory and import the Letters data\n",
    "os.chdir('D:\\MSc2\\Deep Learning Keras\\Task2')\n",
    "data = pd.read_csv('Letters.txt',header=None)\n",
    "\n",
    "#Randomly shuffle the data\n",
    "data = data.iloc[np.random.permutation(data.shape[0]),].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.head() #First column is the label (binary)\n",
    "#data.shape #(20000, 17)\n",
    "#data.describe() #x = 0-15\n",
    "#data.info() #y = object, x = int64\n",
    "#data.columns.values #column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Section 1: Data cleaning and Exploratory Data Analysis\n",
    "#Rename the columns \n",
    "data.columns = [\"Class\"] + [\"Feature\" + str(num1) for num1 in range(1,17)]\n",
    "\n",
    "#Create features and labels\n",
    "y = data['Class'].astype(\"category\") #26 classes - pandas series (type categoy)\n",
    "x = data.iloc[:,1:] #features \n",
    "\n",
    "d = dict(zip(y.unique(), range(0,26))) #{'A': 0, ..., 'Z': 25}\n",
    "y = y.map(d, na_action='ignore') #map the labels of Y: Poissonous - 1, Others - 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the Class Label distributions and the Feature distributions\n",
    "#Class label distribution\n",
    "label_dist = data.iloc[:,0].value_counts().sort_index() #create a table of counts \n",
    "label_dist.plot.bar() #balanced labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check correlation between features using a heat map\n",
    "sns.heatmap(x.corr()) #Feataure 1-5 have much higher correlations than other features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Section 2. Prepare data for modelling\n",
    "n = data.shape[0]\n",
    "k = 0.70\n",
    "q = int(round(n*k))\n",
    "\n",
    "#Standardize features and convert to numpy arrays\n",
    "x = np.asarray(x).astype('float32')\n",
    "x = (x - x.mean(axis = 0))/x.std(axis=0) #x is homogeneous (similar range) - mean 0, std 1\n",
    "#x = (x - x.mean(axis = 0))/(x.max(axis=0) - x.min(axis=0))\n",
    "#x = (x - x.min(axis = 0))/(x.max(axis=0) - x.min(axis=0)) #x takes on small values - lies in [0,1]\n",
    "\n",
    "train_x = x[:q,:] \n",
    "test_x = x[q:,:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1-hot-encode targets y and convert to numpy arrays\n",
    "y = np.asarray(y) #objects\n",
    "y = to_categorical(y)\n",
    "\n",
    "train_y = y[:q,:]\n",
    "test_y = y[q:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#type(train_x), type(train_y), type(test_x), type(test_y) #(numpy.ndarray, numpy.ndarray, numpy.ndarray, numpy.ndarray)\n",
    "#train_x.shape, train_y.shape, test_x.shape, test_y.shape #((14000, 16), (14000, 26), (6000, 16), (6000, 26))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Section 3. Model Building\n",
    "#1)Architecture of the model\n",
    "d = train_x.shape[1]\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(d,)))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(26, activation='softmax')) #26 classes\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy']) #Optimizer, Loss function, Metrics\n",
    "\n",
    "#2)Train the model \n",
    "##K-Fold CV \n",
    "k = 5\n",
    "num_validation_samples = train_x.shape[0] // k\n",
    "loss = []\n",
    "accuracy = []\n",
    "n = 300\n",
    "\n",
    "\n",
    "for i in range(1,n,10): #Hyper-param = # of epochs\n",
    "    l = []\n",
    "    a = []\n",
    "    for fold in range(k): #5 folds\n",
    "        validation_x = train_x[num_validation_samples*fold: num_validation_samples*(fold+1),:]\n",
    "        validation_y = train_y[num_validation_samples*fold: num_validation_samples*(fold+1)]\n",
    "        training_x = np.concatenate( (train_x[:num_validation_samples,:],train_x[num_validation_samples*(fold+1):,:]),\n",
    "                                        axis = 0)\n",
    "        training_y = np.concatenate( (train_y[:num_validation_samples],train_y[num_validation_samples*(fold+1):]),\n",
    "                                        axis = 0)\n",
    "\n",
    "        model.fit(training_x, training_y, epochs=i, batch_size=512,verbose=0) \n",
    "\n",
    "        l.append(model.evaluate(validation_x,validation_y,verbose=0)[0])\n",
    "        a.append(model.evaluate(validation_x,validation_y,verbose=0)[1])\n",
    "        \n",
    "        \n",
    "    loss.append(sum(l)/len(l))\n",
    "    accuracy.append(sum(a)/len(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3)Tuning - Plot loss and accuracy \n",
    "loss_values = np.asarray(loss)\n",
    "accuracy_values = np.asarray(accuracy)\n",
    "\n",
    "epochs = range(1,len(loss_values)+1)\n",
    "plt.plot(epochs,loss_values, 'bo')\n",
    "plt.xticks(range(1, 20,3))\n",
    "plt.title('Loss - CV (k=5)', fontweight = 'bold',fontsize = 16)\n",
    "plt.xlabel('Epochs (in steps of 10)',fontsize = 14)\n",
    "plt.ylabel('Loss',fontsize = 14)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "epochs = range(1,len(accuracy_values)+1)\n",
    "plt.plot(epochs,accuracy_values, 'go')\n",
    "plt.xticks(range(1, 20,3))\n",
    "plt.title('Accuracy - CV (k=5)', fontweight = 'bold',fontsize = 16)\n",
    "plt.xlabel('Epochs (in steps of 10)',fontsize = 14)\n",
    "plt.ylabel('Accuracy',fontsize = 14)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4)Finalize - retraining the model using whole training set\n",
    "d = train_x.shape[1]\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(d,)))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(26, activation='softmax')) #26 classes\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy']) #Optimizer, Loss function, Metrics\n",
    "\n",
    "model.fit(train_x, train_y, epochs=150,batch_size=512,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5)Evaluate on the test set\n",
    "model.evaluate(test_x,test_y) #[loss, accuracy] = [0.18193856616318227, 0.9406666666666667]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6)Closer look at the test set performance\n",
    "predictions = model.predict(test_x, verbose=0) #see the soft probability of the predicted data\n",
    "plt.hist(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random baseline model(multiclass classification)\n",
    "test_y = np.asarray(data.iloc[q:,0])\n",
    "test_y_copy = copy.copy(test_y)\n",
    "np.random.shuffle(test_y_copy)\n",
    "hits_array = np.array(test_y) == np.array(test_y_copy)\n",
    "float(np.sum(hits_array))/len(test_y)\n",
    "\n",
    "#a random guess tends to get an accuracy of 0.041166666666666664"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
